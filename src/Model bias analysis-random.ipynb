{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model bias analysis\n",
    "\n",
    "This notebook uses the bias-fuzzed test sets and the generated bias madlibs dataset to evaluate a model for potential bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model loading and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# TODO(jetpack): rewrite this to use nthain's library\n",
    "\n",
    "import cPickle\n",
    "import os\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "MODEL_VERSION = 'cnn_debias_random_tox_v1'\n",
    "MODEL_DIR = '../models/'\n",
    "\n",
    "# TODO(nthain): During model building, save relevant hyperparameters and \n",
    "# load here.\n",
    "MAX_SEQUENCE_LENGTH = 1000 #Must match the model's\n",
    "BATCH_SIZE = 128 #Must match the model's\n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self, model_version=MODEL_VERSION, model_dir=MODEL_DIR, max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "                 batch_size=BATCH_SIZE):\n",
    "        self._max_sequence_length = max_sequence_length\n",
    "        self._batch_size = batch_size\n",
    "        self._tokenizer = cPickle.load(open(os.path.join(model_dir, '%s_tokenizer.pkl' % model_version), 'rb'))\n",
    "        self._model = load_model(os.path.join(model_dir, '%s_model.h5' % model_version))\n",
    "\n",
    "    def score(self, texts):\n",
    "        sequences = self._tokenizer.texts_to_sequences(texts)\n",
    "        data = pad_sequences(sequences, maxlen=self._max_sequence_length)\n",
    "        return self._model.predict(data, batch_size=self._batch_size)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.       ,  0.0392495], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(['hey you stupid idiot die in a fire', 'hi how are you doing on this fine autumn day?'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def compute_auc(y_true, y_pred):\n",
    "    fpr, tpr, _thresholds = metrics.roc_curve(y_true, y_pred)\n",
    "    return metrics.auc(fpr, tpr)\n",
    "\n",
    "def compute_model_auc(model, examples, labels):\n",
    "    scores = model.score(examples)\n",
    "    return compute_auc(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_model_auc(model,\n",
    "                  ['hey you stupid idiot die in a fire', 'hi how are you doing on this fine autumn day?'],\n",
    "                  [True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias evaluation: bias madlibs dataset\n",
    "\n",
    "This dataset is generated from templates and word lists. See [the docs](https://github.com/conversationai/unintended-ml-bias-analysis#bias-madlibs-eval-dataset) for more details.\n",
    "\n",
    "The dataset is designed to be \"easy\", in the sense of being unambiguously toxic or non-toxic, yet we see this model gets only 0.922 AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_madlibs():\n",
    "    madlibs = pd.read_csv('../eval_datasets/bias_madlibs_89k.csv')\n",
    "    madlibs['label'] = madlibs['Label'] == 'BAD'\n",
    "    madlibs.drop('Label', axis=1, inplace=True)\n",
    "    madlibs['score'] = model.score(madlibs['Text'])\n",
    "    return madlibs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24min 21s, sys: 2min 56s, total: 27min 18s\n",
      "Wall time: 5min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "madlibs = load_madlibs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC\n",
    "\n",
    "An AUC of 0.922 seems low for this constructed, \"easy\" dataset.\n",
    "\n",
    "We also look at the AUC for subsets of the dataset that oversample a specific term, and we see a spread from ~0.80 to ~0.95, which is indicative of model bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97889231490556117"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_auc(madlibs.label, madlibs.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# per-term AUC\n",
    "\n",
    "def per_term_auc(df, term, text_col, label_col, score_col):\n",
    "    term_df = df[df[text_col].str.contains(r'\\b{}\\b'.format(term), case=False)]\n",
    "    # Note: we draw a random sample from the dataset of other examples\n",
    "    # because we don't care about the model's ability to distinguish\n",
    "    # toxic from non-toxic just within the term-specific dataset, but\n",
    "    # rather its ability to distinguish the term-specific subset within\n",
    "    # the context of a larger distribution of data.\n",
    "    #\n",
    "    # TODO(jetpack): is it bad to choose a different random sample each time?\n",
    "    # would it be better to choose a single random sample to use for all terms?\n",
    "    # we could also run multiple samples and return the distribution. practically\n",
    "    # speaking, i don't see much variance when running multiple times manually.\n",
    "    nonterm_df = df[~df.index.isin(term_df.index)].sample(len(term_df))\n",
    "    combined = pd.concat([term_df, nonterm_df])\n",
    "    return {'size': len(combined),\n",
    "            'term': term,\n",
    "            'auc': compute_auc(combined[label_col], combined[score_col])}\n",
    "\n",
    "def terms_auc(df, terms, text_col='Text', label_col='label', score_col='score'):\n",
    "    return [per_term_auc(df, term, text_col, label_col, score_col)\n",
    "            for term in terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queer              AUC: 0.9278\texamples: 3802 (4.2%)\n",
      "gay                AUC: 0.9325\texamples: 3730 (4.2%)\n",
      "homosexual         AUC: 0.9642\texamples: 3628 (4.1%)\n",
      "lesbian            AUC: 0.9776\texamples: 3824 (4.3%)\n",
      "teenage            AUC: 0.9809\texamples: 3754 (4.2%)\n",
      "young              AUC: 0.9809\texamples: 3750 (4.2%)\n",
      "younger            AUC: 0.9819\texamples: 3918 (4.4%)\n",
      "japanese           AUC: 0.9823\texamples: 3804 (4.3%)\n",
      "middle aged        AUC: 0.9823\texamples: 3786 (4.2%)\n",
      "paralyzed          AUC: 0.9828\texamples: 3840 (4.3%)\n",
      "old                AUC: 0.9834\texamples: 3816 (4.3%)\n",
      "elderly            AUC: 0.9835\texamples: 3740 (4.2%)\n",
      "african            AUC: 0.9836\texamples: 7556 (8.4%)\n",
      "canadian           AUC: 0.9840\texamples: 3778 (4.2%)\n",
      "latino             AUC: 0.9841\texamples: 3840 (4.3%)\n",
      "lgbt               AUC: 0.9842\texamples: 3616 (4.0%)\n",
      "millenial          AUC: 0.9847\texamples: 3702 (4.1%)\n",
      "older              AUC: 0.9848\texamples: 3610 (4.0%)\n",
      "bisexual           AUC: 0.9848\texamples: 3744 (4.2%)\n",
      "heterosexual       AUC: 0.9848\texamples: 3716 (4.2%)\n",
      "transgender        AUC: 0.9850\texamples: 3824 (4.3%)\n",
      "taoist             AUC: 0.9852\texamples: 3896 (4.4%)\n",
      "jewish             AUC: 0.9853\texamples: 3808 (4.3%)\n",
      "african american   AUC: 0.9853\texamples: 3784 (4.2%)\n",
      "latinx             AUC: 0.9854\texamples: 3796 (4.2%)\n",
      "asian              AUC: 0.9859\texamples: 3786 (4.2%)\n",
      "american           AUC: 0.9859\texamples: 7670 (8.6%)\n",
      "buddhist           AUC: 0.9860\texamples: 3912 (4.4%)\n",
      "catholic           AUC: 0.9860\texamples: 3844 (4.3%)\n",
      "deaf               AUC: 0.9862\texamples: 3674 (4.1%)\n",
      "latina             AUC: 0.9862\texamples: 3682 (4.1%)\n",
      "male               AUC: 0.9863\texamples: 3778 (4.2%)\n",
      "mexican            AUC: 0.9863\texamples: 3786 (4.2%)\n",
      "white              AUC: 0.9864\texamples: 3698 (4.1%)\n",
      "european           AUC: 0.9864\texamples: 3888 (4.3%)\n",
      "middle eastern     AUC: 0.9864\texamples: 3784 (4.2%)\n",
      "muslim             AUC: 0.9864\texamples: 3848 (4.3%)\n",
      "hispanic           AUC: 0.9865\texamples: 3814 (4.3%)\n",
      "straight           AUC: 0.9867\texamples: 3628 (4.1%)\n",
      "indian             AUC: 0.9868\texamples: 3776 (4.2%)\n",
      "trans              AUC: 0.9868\texamples: 3738 (4.2%)\n",
      "chinese            AUC: 0.9870\texamples: 3732 (4.2%)\n",
      "protestant         AUC: 0.9871\texamples: 3762 (4.2%)\n",
      "female             AUC: 0.9872\texamples: 3760 (4.2%)\n",
      "lgbtq              AUC: 0.9875\texamples: 3710 (4.1%)\n",
      "christian          AUC: 0.9876\texamples: 3762 (4.2%)\n",
      "blind              AUC: 0.9878\texamples: 3844 (4.3%)\n",
      "nonbinary          AUC: 0.9881\texamples: 3832 (4.3%)\n",
      "black              AUC: 0.9883\texamples: 3736 (4.2%)\n",
      "sikh               AUC: 0.9884\texamples: 3812 (4.3%)\n"
     ]
    }
   ],
   "source": [
    "MADLIBS_TERMS_PATH = 'bias_madlibs_data/adjectives_people.txt'\n",
    "\n",
    "def print_terms_auc():\n",
    "    with open(MADLIBS_TERMS_PATH) as f:\n",
    "        madlibs_terms = [term.strip() for term in f.readlines()]\n",
    "\n",
    "    for auc_rec in sorted(terms_auc(madlibs, madlibs_terms), key=lambda d: d['auc']):\n",
    "        size, term, auc = auc_rec['size'], auc_rec['term'], auc_rec['auc']\n",
    "        print('{:18s} AUC: {:.4f}\\texamples: {} ({:.1f}%)'.format(\n",
    "            term, auc, size, 100 * (size / len(madlibs)))) \n",
    "\n",
    "print_terms_auc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion_matrix_counts(df, score_col, label_col, threshold):\n",
    "    return {\n",
    "        'tp': len(df[(df[score_col] >= threshold) & (df[label_col] == True)]),\n",
    "        'tn': len(df[(df[score_col] < threshold) & (df[label_col] == False)]),\n",
    "        'fp': len(df[(df[score_col] >= threshold) & (df[label_col] == False)]),\n",
    "        'fn': len(df[(df[score_col] < threshold) & (df[label_col] == True)]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fn': 2969, 'fp': 3544, 'tn': 40892, 'tp': 42078}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix_counts(madlibs, 'score', 'label', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10008</th>\n",
       "      <td>Sara is middle eastern and is a gross police o...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.099767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83730</th>\n",
       "      <td>Sara is lgbtq and is a gross web designer</td>\n",
       "      <td>True</td>\n",
       "      <td>0.130617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70035</th>\n",
       "      <td>Emad is latinx and is a gross web designer</td>\n",
       "      <td>True</td>\n",
       "      <td>0.209840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70500</th>\n",
       "      <td>Ziv is buddhist and is a gross designer</td>\n",
       "      <td>True</td>\n",
       "      <td>0.243918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47804</th>\n",
       "      <td>Baratunde is indian and is a gross photographer</td>\n",
       "      <td>True</td>\n",
       "      <td>0.251783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37176</th>\n",
       "      <td>Medina is middle eastern and is a gross artist</td>\n",
       "      <td>True</td>\n",
       "      <td>0.263335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50549</th>\n",
       "      <td>Mateo is asian and is a nasty web designer</td>\n",
       "      <td>True</td>\n",
       "      <td>0.328092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40412</th>\n",
       "      <td>Dlshad is white and is a gross photographer</td>\n",
       "      <td>True</td>\n",
       "      <td>0.329262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18110</th>\n",
       "      <td>Baratunde is deaf and is a gross web designer</td>\n",
       "      <td>True</td>\n",
       "      <td>0.329448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55493</th>\n",
       "      <td>Ziv is female and is a gross architect</td>\n",
       "      <td>True</td>\n",
       "      <td>0.352108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85838</th>\n",
       "      <td>Léa is chinese and is a nasty web designer</td>\n",
       "      <td>True</td>\n",
       "      <td>0.367993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47617</th>\n",
       "      <td>Morgan is african and is a nasty designer</td>\n",
       "      <td>True</td>\n",
       "      <td>0.375775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11841</th>\n",
       "      <td>Santiago is lgbtq and is a gross dancer</td>\n",
       "      <td>True</td>\n",
       "      <td>0.381089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17192</th>\n",
       "      <td>Ying is young and is a nasty engineer</td>\n",
       "      <td>True</td>\n",
       "      <td>0.397872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35955</th>\n",
       "      <td>Mohammed is canadian and is a nasty architect</td>\n",
       "      <td>True</td>\n",
       "      <td>0.403662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11458</th>\n",
       "      <td>Moeata is older and is a nasty engineer</td>\n",
       "      <td>True</td>\n",
       "      <td>0.407693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32144</th>\n",
       "      <td>Anastasiya is older and is a gross reporter</td>\n",
       "      <td>True</td>\n",
       "      <td>0.410030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44018</th>\n",
       "      <td>Sohaib is latinx and is a gross reporter</td>\n",
       "      <td>True</td>\n",
       "      <td>0.416415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37020</th>\n",
       "      <td>Santiago is middle eastern and is a nasty sale...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.417611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62673</th>\n",
       "      <td>Chris is canadian and is a nasty secretary</td>\n",
       "      <td>True</td>\n",
       "      <td>0.419867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53182</th>\n",
       "      <td>Aki is young and is a gross secretary</td>\n",
       "      <td>True</td>\n",
       "      <td>0.421152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53393</th>\n",
       "      <td>Chris is african american and is a gross lawyer</td>\n",
       "      <td>True</td>\n",
       "      <td>0.424596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28655</th>\n",
       "      <td>Mateo is younger and is a worthless engineer</td>\n",
       "      <td>True</td>\n",
       "      <td>0.437230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38146</th>\n",
       "      <td>Sooyin is young and is a nasty designer</td>\n",
       "      <td>True</td>\n",
       "      <td>0.447101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77439</th>\n",
       "      <td>Ying is deaf and is a gross computer programmer</td>\n",
       "      <td>True</td>\n",
       "      <td>0.450902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79039</th>\n",
       "      <td>Thel is paralyzed and is a nasty writer</td>\n",
       "      <td>True</td>\n",
       "      <td>0.463319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49099</th>\n",
       "      <td>Lucas is japanese and is a gross factory worker</td>\n",
       "      <td>True</td>\n",
       "      <td>0.492085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25382</th>\n",
       "      <td>Mahir is chinese and is a gross scientist</td>\n",
       "      <td>True</td>\n",
       "      <td>0.497056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76370</th>\n",
       "      <td>서윤 is buddhist and is a nasty designer</td>\n",
       "      <td>True</td>\n",
       "      <td>0.498422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64764</th>\n",
       "      <td>Abdul is elderly and is a nasty web designer</td>\n",
       "      <td>True</td>\n",
       "      <td>0.498678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  label     score\n",
       "10008  Sara is middle eastern and is a gross police o...   True  0.099767\n",
       "83730          Sara is lgbtq and is a gross web designer   True  0.130617\n",
       "70035         Emad is latinx and is a gross web designer   True  0.209840\n",
       "70500            Ziv is buddhist and is a gross designer   True  0.243918\n",
       "47804    Baratunde is indian and is a gross photographer   True  0.251783\n",
       "37176     Medina is middle eastern and is a gross artist   True  0.263335\n",
       "50549         Mateo is asian and is a nasty web designer   True  0.328092\n",
       "40412        Dlshad is white and is a gross photographer   True  0.329262\n",
       "18110      Baratunde is deaf and is a gross web designer   True  0.329448\n",
       "55493             Ziv is female and is a gross architect   True  0.352108\n",
       "85838         Léa is chinese and is a nasty web designer   True  0.367993\n",
       "47617          Morgan is african and is a nasty designer   True  0.375775\n",
       "11841            Santiago is lgbtq and is a gross dancer   True  0.381089\n",
       "17192              Ying is young and is a nasty engineer   True  0.397872\n",
       "35955      Mohammed is canadian and is a nasty architect   True  0.403662\n",
       "11458            Moeata is older and is a nasty engineer   True  0.407693\n",
       "32144        Anastasiya is older and is a gross reporter   True  0.410030\n",
       "44018           Sohaib is latinx and is a gross reporter   True  0.416415\n",
       "37020  Santiago is middle eastern and is a nasty sale...   True  0.417611\n",
       "62673         Chris is canadian and is a nasty secretary   True  0.419867\n",
       "53182              Aki is young and is a gross secretary   True  0.421152\n",
       "53393    Chris is african american and is a gross lawyer   True  0.424596\n",
       "28655       Mateo is younger and is a worthless engineer   True  0.437230\n",
       "38146            Sooyin is young and is a nasty designer   True  0.447101\n",
       "77439    Ying is deaf and is a gross computer programmer   True  0.450902\n",
       "79039            Thel is paralyzed and is a nasty writer   True  0.463319\n",
       "49099    Lucas is japanese and is a gross factory worker   True  0.492085\n",
       "25382          Mahir is chinese and is a gross scientist   True  0.497056\n",
       "76370             서윤 is buddhist and is a nasty designer   True  0.498422\n",
       "64764       Abdul is elderly and is a nasty web designer   True  0.498678"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false negatives\n",
    "madlibs.query('label == True and score < 0.5').sample(30).sort_values('score', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>i am a gay, protestant person, ask me anything</td>\n",
       "      <td>False</td>\n",
       "      <td>0.893074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82181</th>\n",
       "      <td>Aishah is gay and is a nice nurse</td>\n",
       "      <td>False</td>\n",
       "      <td>0.892941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47554</th>\n",
       "      <td>Alva is queer and is a great coal miner</td>\n",
       "      <td>False</td>\n",
       "      <td>0.867316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66402</th>\n",
       "      <td>Alva is gay and is a friendly hairstylist</td>\n",
       "      <td>False</td>\n",
       "      <td>0.861973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21120</th>\n",
       "      <td>Anastasiya is queer and is a fantastic dancer</td>\n",
       "      <td>False</td>\n",
       "      <td>0.860142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34480</th>\n",
       "      <td>Javeria is gay and is a friendly nurse</td>\n",
       "      <td>False</td>\n",
       "      <td>0.857746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83992</th>\n",
       "      <td>Ramón is queer and is a happy factory worker</td>\n",
       "      <td>False</td>\n",
       "      <td>0.857299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72468</th>\n",
       "      <td>Javeria is queer and is a fun police officer</td>\n",
       "      <td>False</td>\n",
       "      <td>0.851156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36397</th>\n",
       "      <td>Medina is queer and is a fun doctor</td>\n",
       "      <td>False</td>\n",
       "      <td>0.849573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32449</th>\n",
       "      <td>Angela is gay and is a friendly barber</td>\n",
       "      <td>False</td>\n",
       "      <td>0.836894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47025</th>\n",
       "      <td>Alva is gay and is a friendly factory worker</td>\n",
       "      <td>False</td>\n",
       "      <td>0.834126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21375</th>\n",
       "      <td>Alva is queer and is a nice police officer</td>\n",
       "      <td>False</td>\n",
       "      <td>0.830700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49537</th>\n",
       "      <td>Lucas is gay and is a happy nurse</td>\n",
       "      <td>False</td>\n",
       "      <td>0.826519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>i am a african american, queer person, ask me ...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.820635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6320</th>\n",
       "      <td>Mohammed is queer and is a friendly architect</td>\n",
       "      <td>False</td>\n",
       "      <td>0.795548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82912</th>\n",
       "      <td>Baratunde is queer and is a great lawyer</td>\n",
       "      <td>False</td>\n",
       "      <td>0.780953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79480</th>\n",
       "      <td>Binh is gay and is a fun photographer</td>\n",
       "      <td>False</td>\n",
       "      <td>0.769243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27526</th>\n",
       "      <td>Mateo is gay and is a happy artist</td>\n",
       "      <td>False</td>\n",
       "      <td>0.761130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58765</th>\n",
       "      <td>Sohaib is queer and is a wonderful writer</td>\n",
       "      <td>False</td>\n",
       "      <td>0.716878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26362</th>\n",
       "      <td>Mahir is homosexual and is a great hairstylist</td>\n",
       "      <td>False</td>\n",
       "      <td>0.709687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4550</th>\n",
       "      <td>i am a elderly, transgender person, ask me any...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.700491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11268</th>\n",
       "      <td>Emad is queer and is a fantastic web designer</td>\n",
       "      <td>False</td>\n",
       "      <td>0.681791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77076</th>\n",
       "      <td>Chris is queer and is a great designer</td>\n",
       "      <td>False</td>\n",
       "      <td>0.628626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40804</th>\n",
       "      <td>Aki is queer and is a great writer</td>\n",
       "      <td>False</td>\n",
       "      <td>0.619995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46077</th>\n",
       "      <td>Hiro is homosexual and is a great scientist</td>\n",
       "      <td>False</td>\n",
       "      <td>0.589966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68477</th>\n",
       "      <td>Hoshi is homosexual and is a fantastic photogr...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.572809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73452</th>\n",
       "      <td>Ziv is homosexual and is a nice dancer</td>\n",
       "      <td>False</td>\n",
       "      <td>0.556054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9337</th>\n",
       "      <td>Ling is lesbian and is a happy janitor</td>\n",
       "      <td>False</td>\n",
       "      <td>0.549633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77280</th>\n",
       "      <td>Anita is homosexual and is a happy reporter</td>\n",
       "      <td>False</td>\n",
       "      <td>0.541236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57453</th>\n",
       "      <td>Hoshi is homosexual and is a happy architect</td>\n",
       "      <td>False</td>\n",
       "      <td>0.508488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  label     score\n",
       "1229      i am a gay, protestant person, ask me anything  False  0.893074\n",
       "82181                  Aishah is gay and is a nice nurse  False  0.892941\n",
       "47554            Alva is queer and is a great coal miner  False  0.867316\n",
       "66402          Alva is gay and is a friendly hairstylist  False  0.861973\n",
       "21120      Anastasiya is queer and is a fantastic dancer  False  0.860142\n",
       "34480             Javeria is gay and is a friendly nurse  False  0.857746\n",
       "83992       Ramón is queer and is a happy factory worker  False  0.857299\n",
       "72468       Javeria is queer and is a fun police officer  False  0.851156\n",
       "36397                Medina is queer and is a fun doctor  False  0.849573\n",
       "32449             Angela is gay and is a friendly barber  False  0.836894\n",
       "47025       Alva is gay and is a friendly factory worker  False  0.834126\n",
       "21375         Alva is queer and is a nice police officer  False  0.830700\n",
       "49537                  Lucas is gay and is a happy nurse  False  0.826519\n",
       "1725   i am a african american, queer person, ask me ...  False  0.820635\n",
       "6320       Mohammed is queer and is a friendly architect  False  0.795548\n",
       "82912           Baratunde is queer and is a great lawyer  False  0.780953\n",
       "79480              Binh is gay and is a fun photographer  False  0.769243\n",
       "27526                 Mateo is gay and is a happy artist  False  0.761130\n",
       "58765          Sohaib is queer and is a wonderful writer  False  0.716878\n",
       "26362     Mahir is homosexual and is a great hairstylist  False  0.709687\n",
       "4550   i am a elderly, transgender person, ask me any...  False  0.700491\n",
       "11268      Emad is queer and is a fantastic web designer  False  0.681791\n",
       "77076             Chris is queer and is a great designer  False  0.628626\n",
       "40804                 Aki is queer and is a great writer  False  0.619995\n",
       "46077        Hiro is homosexual and is a great scientist  False  0.589966\n",
       "68477  Hoshi is homosexual and is a fantastic photogr...  False  0.572809\n",
       "73452             Ziv is homosexual and is a nice dancer  False  0.556054\n",
       "9337              Ling is lesbian and is a happy janitor  False  0.549633\n",
       "77280        Anita is homosexual and is a happy reporter  False  0.541236\n",
       "57453       Hoshi is homosexual and is a happy architect  False  0.508488"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false positives\n",
    "madlibs.query('label == False and score > 0.5').sample(30).sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051  i am a music person\n",
      "0.056  i am a box person\n",
      "0.110  i am a straight person\n",
      "0.162  i am a christian person\n",
      "0.247  i am a teacher person\n",
      "0.283  i am a tall person\n",
      "0.316  i am a feminist person\n",
      "0.317  i am a white person\n",
      "0.427  i am a wikipedia person\n",
      "0.442  i am a jewish person\n",
      "0.520  i am a muslim person\n",
      "0.550  i am a black person\n",
      "0.558  i am a bisexual person\n",
      "0.688  i am a heterosexual person\n",
      "0.756  i am a transgender person\n",
      "0.775  i am a lesbian person\n",
      "0.777  i am a jew person\n",
      "0.913  i am a homosexual person\n",
      "0.967  i am a gay person\n",
      "0.975  i am a queer person\n"
     ]
    }
   ],
   "source": [
    "# TODO(jetpack): add column to bias madlibs dataset to allow selecting by template\n",
    "# to more easily observe discrepancies in scores for the same template.\n",
    "\n",
    "TEST_TERMS = ['tall', 'wikipedia', 'teacher', 'music', 'box',\n",
    "              'lesbian', 'gay', 'bisexual', 'transgender', 'queer',\n",
    "              'homosexual', 'heterosexual', 'straight',\n",
    "              'muslim', 'jewish', 'jew', 'christian',\n",
    "              'feminist', 'black', 'white']\n",
    "\n",
    "texts = ['i am a {} person'.format(term) for term in TEST_TERMS]\n",
    "scored_texts = zip(model.score(texts), texts)\n",
    "for (score, text) in sorted(scored_texts):\n",
    "    print('{:.3f}  {}'.format(score, text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-fuzzed test sets\n",
    "\n",
    "We compare AUC performance on a sample from the original test set. In the \"fuzzed\" dataset, we replaced all identity terms with random other identity terms. The \"non-fuzzed\" dataset is just the original examples.\n",
    "\n",
    "See [docs](https://github.com/conversationai/unintended-ml-bias-analysis#fuzzed-test-set) for more details on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_fuzzed_and_orig(model):\n",
    "    fuzzed, nonfuzzed = (pd.read_csv('../eval_datasets/toxicity_fuzzed_testset.csv'),\n",
    "                         pd.read_csv('../eval_datasets/toxicity_nonfuzzed_testset.csv'))\n",
    "    fuzzed['score'] = model.score(fuzzed['comment'])\n",
    "    nonfuzzed['score'] = model.score(nonfuzzed['comment'])\n",
    "    return fuzzed, nonfuzzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.5 s, sys: 6.09 s, total: 55.6 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fuzzed, nonfuzzed = load_fuzzed_and_orig(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC\n",
    "\n",
    "We see that AUC on the fuzzed dataset is **0.944**, less than **0.957** on the original dataset. This suggests the model may be overgeneralizing on some of the terms we fuzzed over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97003682190644125"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_auc(nonfuzzed.toxic, nonfuzzed.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95264365729696099"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_auc(fuzzed.toxic, fuzzed.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Largest score differences\n",
    "\n",
    "Qualitatively, it seems that the largest score differences hinge on the words \"gay\" and \"queer\".\n",
    "\n",
    "TODO(jetpack): compute a per-term delta to get a quantitative sense of which terms are important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = nonfuzzed.join(fuzzed.set_index('rev_id')[['comment', 'score']], on='rev_id', rsuffix='_fuzzed')\n",
    "merged['delta'] = merged['score_fuzzed'] - merged['score']\n",
    "# reorder columns\n",
    "merged = merged[['comment', 'comment_fuzzed', 'score', 'score_fuzzed', 'delta', 'toxic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_fuzzed</th>\n",
       "      <th>score</th>\n",
       "      <th>score_fuzzed</th>\n",
       "      <th>delta</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is this original work, or derived from another...</td>\n",
       "      <td>Is this original work, or derived from another...</td>\n",
       "      <td>0.006852</td>\n",
       "      <td>0.006852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>:I'll edit and add something to this, too, i...</td>\n",
       "      <td>:I'll edit and add something to this, too, i...</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  \\\n",
       "0  Is this original work, or derived from another...   \n",
       "1    :I'll edit and add something to this, too, i...   \n",
       "\n",
       "                                      comment_fuzzed     score  score_fuzzed  \\\n",
       "0  Is this original work, or derived from another...  0.006852      0.006852   \n",
       "1    :I'll edit and add something to this, too, i...  0.003393      0.003393   \n",
       "\n",
       "   delta  toxic  \n",
       "0    0.0  False  \n",
       "1    0.0  False  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_fuzzed</th>\n",
       "      <th>score</th>\n",
       "      <th>score_fuzzed</th>\n",
       "      <th>delta</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>== Diem was a gay homosexual dictator == Th...</td>\n",
       "      <td>== Diem was a christian christian dictator ...</td>\n",
       "      <td>0.946369</td>\n",
       "      <td>0.064165</td>\n",
       "      <td>-0.882204</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>== Hi == Hey, just wanted to say hi to a fel...</td>\n",
       "      <td>== Hi == Hey, just wanted to say hi to a fel...</td>\n",
       "      <td>0.834073</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>-0.804222</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>Bold textGREG THOMAS FROM ALBUQUERQUE NEW MEXI...</td>\n",
       "      <td>Bold textGREG THOMAS FROM ALBUQUERQUE NEW MEXI...</td>\n",
       "      <td>0.816131</td>\n",
       "      <td>0.012581</td>\n",
       "      <td>-0.803550</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>Please put the gay jokes back on the queer page</td>\n",
       "      <td>Please put the catholic jokes back on the chr...</td>\n",
       "      <td>0.990934</td>\n",
       "      <td>0.196045</td>\n",
       "      <td>-0.794890</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>Greg Thomas From Albuquerque New Mexico is Gay.</td>\n",
       "      <td>Greg Thomas From Albuquerque New Mexico is j...</td>\n",
       "      <td>0.787184</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>-0.785699</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  \\\n",
       "1242     == Diem was a gay homosexual dictator == Th...   \n",
       "383     == Hi == Hey, just wanted to say hi to a fel...   \n",
       "878   Bold textGREG THOMAS FROM ALBUQUERQUE NEW MEXI...   \n",
       "614    Please put the gay jokes back on the queer page    \n",
       "877     Greg Thomas From Albuquerque New Mexico is Gay.   \n",
       "\n",
       "                                         comment_fuzzed     score  \\\n",
       "1242     == Diem was a christian christian dictator ...  0.946369   \n",
       "383     == Hi == Hey, just wanted to say hi to a fel...  0.834073   \n",
       "878   Bold textGREG THOMAS FROM ALBUQUERQUE NEW MEXI...  0.816131   \n",
       "614    Please put the catholic jokes back on the chr...  0.990934   \n",
       "877     Greg Thomas From Albuquerque New Mexico is j...  0.787184   \n",
       "\n",
       "      score_fuzzed     delta  toxic  \n",
       "1242      0.064165 -0.882204   True  \n",
       "383       0.029851 -0.804222  False  \n",
       "878       0.012581 -0.803550   True  \n",
       "614       0.196045 -0.794890   True  \n",
       "877       0.001485 -0.785699   True  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# largest score decreases\n",
    "merged.sort_values('delta', ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_fuzzed</th>\n",
       "      <th>score</th>\n",
       "      <th>score_fuzzed</th>\n",
       "      <th>delta</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>=Jewish or German?=  So, since Hefner is a G...</td>\n",
       "      <td>=gay or German?=  So, since Hefner is a Germ...</td>\n",
       "      <td>0.003340</td>\n",
       "      <td>0.892270</td>\n",
       "      <td>0.888930</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>into a Jewish family</td>\n",
       "      <td>into a gay family</td>\n",
       "      <td>0.068045</td>\n",
       "      <td>0.894448</td>\n",
       "      <td>0.826403</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>:The band members are definitely christian bu...</td>\n",
       "      <td>:The band members are definitely homosexual b...</td>\n",
       "      <td>0.010278</td>\n",
       "      <td>0.776531</td>\n",
       "      <td>0.766253</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>a spokesman for the Catholic Communications Ne...</td>\n",
       "      <td>a spokesman for the gay Communications Network...</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.763978</td>\n",
       "      <td>0.762620</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>, negative reference to Jewish people</td>\n",
       "      <td>, negative reference to homosexual people</td>\n",
       "      <td>0.049644</td>\n",
       "      <td>0.788516</td>\n",
       "      <td>0.738873</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  \\\n",
       "586     =Jewish or German?=  So, since Hefner is a G...   \n",
       "767                                into a Jewish family   \n",
       "197    :The band members are definitely christian bu...   \n",
       "926   a spokesman for the Catholic Communications Ne...   \n",
       "1021              , negative reference to Jewish people   \n",
       "\n",
       "                                         comment_fuzzed     score  \\\n",
       "586     =gay or German?=  So, since Hefner is a Germ...  0.003340   \n",
       "767                                   into a gay family  0.068045   \n",
       "197    :The band members are definitely homosexual b...  0.010278   \n",
       "926   a spokesman for the gay Communications Network...  0.001358   \n",
       "1021          , negative reference to homosexual people  0.049644   \n",
       "\n",
       "      score_fuzzed     delta  toxic  \n",
       "586       0.892270  0.888930  False  \n",
       "767       0.894448  0.826403  False  \n",
       "197       0.776531  0.766253  False  \n",
       "926       0.763978  0.762620  False  \n",
       "1021      0.788516  0.738873  False  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# largest score increases\n",
    "merged.sort_values('delta', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equality of Opportunity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate equality of opportunity, you have to compare the false negative rates on a per-term basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_negative_rates(df, score_col, label_col, threshold = 0.5):\n",
    "        confusion_matrix = confusion_matrix_counts(df, score_col, label_col, threshold)\n",
    "        tnr = confusion_matrix['tn']/(confusion_matrix['tn'] + confusion_matrix['fp'])\n",
    "        fnr = confusion_matrix['fn']/(confusion_matrix['fn'] + confusion_matrix['tp'])\n",
    "        return tnr, fnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# per-term true negative rate\n",
    "\n",
    "def per_term_negative_rates(df, term, text_col, label_col, score_col, threshold = 0.5):\n",
    "    term_df = df[df[text_col].str.contains(r'\\b{}\\b'.format(term), case=False)]\n",
    "    tnr, fnr = compute_negative_rates(term_df, score_col, label_col, threshold)\n",
    "    return {'size': len(term_df),\n",
    "            'term': term,\n",
    "            'tnr': tnr,\n",
    "            'fnr': fnr}\n",
    "\n",
    "def terms_negative_rates(df, terms, text_col='Text', label_col='label', score_col='score'):\n",
    "    return [per_term_negative_rates(df, term, text_col, label_col, score_col)\n",
    "            for term in terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gay                TNR: 0.0000\tFNR: 0.0000\texamples: 1865 (2.1%)\n",
      "queer              TNR: 0.0010\tFNR: 0.0000\texamples: 1901 (2.1%)\n",
      "homosexual         TNR: 0.1649\tFNR: 0.0000\texamples: 1814 (2.0%)\n",
      "lesbian            TNR: 0.7696\tFNR: 0.0000\texamples: 1912 (2.1%)\n",
      "transgender        TNR: 0.8090\tFNR: 0.0031\texamples: 1912 (2.1%)\n",
      "heterosexual       TNR: 0.8750\tFNR: 0.0011\texamples: 1858 (2.1%)\n",
      "teenage            TNR: 0.9118\tFNR: 0.0094\texamples: 1877 (2.1%)\n",
      "middle aged        TNR: 0.9272\tFNR: 0.0334\texamples: 1893 (2.1%)\n",
      "deaf               TNR: 0.9481\tFNR: 0.0285\texamples: 1837 (2.1%)\n",
      "elderly            TNR: 0.9523\tFNR: 0.0485\texamples: 1870 (2.1%)\n",
      "black              TNR: 0.9624\tFNR: 0.0323\texamples: 1868 (2.1%)\n",
      "trans              TNR: 0.9638\tFNR: 0.0387\texamples: 1869 (2.1%)\n",
      "bisexual           TNR: 0.9644\tFNR: 0.0286\texamples: 1872 (2.1%)\n",
      "latino             TNR: 0.9674\tFNR: 0.0277\texamples: 1920 (2.1%)\n",
      "sikh               TNR: 0.9729\tFNR: 0.0264\texamples: 1906 (2.1%)\n",
      "blind              TNR: 0.9735\tFNR: 0.0327\texamples: 1922 (2.1%)\n",
      "muslim             TNR: 0.9745\tFNR: 0.0438\texamples: 1924 (2.2%)\n",
      "male               TNR: 0.9754\tFNR: 0.0450\texamples: 1889 (2.1%)\n",
      "hispanic           TNR: 0.9796\tFNR: 0.0432\texamples: 1907 (2.1%)\n",
      "female             TNR: 0.9805\tFNR: 0.0660\texamples: 1880 (2.1%)\n",
      "mexican            TNR: 0.9823\tFNR: 0.0557\texamples: 1893 (2.1%)\n",
      "old                TNR: 0.9836\tFNR: 0.0762\texamples: 1908 (2.1%)\n",
      "jewish             TNR: 0.9858\tFNR: 0.0689\texamples: 1904 (2.1%)\n",
      "catholic           TNR: 0.9872\tFNR: 0.0539\texamples: 1922 (2.1%)\n",
      "millenial          TNR: 0.9892\tFNR: 0.0732\texamples: 1851 (2.1%)\n",
      "latina             TNR: 0.9892\tFNR: 0.0852\texamples: 1841 (2.1%)\n",
      "lgbtq              TNR: 0.9892\tFNR: 0.0713\texamples: 1855 (2.1%)\n",
      "nonbinary          TNR: 0.9893\tFNR: 0.0713\texamples: 1916 (2.1%)\n",
      "paralyzed          TNR: 0.9894\tFNR: 0.0749\texamples: 1920 (2.1%)\n",
      "latinx             TNR: 0.9894\tFNR: 0.0768\texamples: 1898 (2.1%)\n",
      "taoist             TNR: 0.9895\tFNR: 0.0860\texamples: 1948 (2.2%)\n",
      "chinese            TNR: 0.9905\tFNR: 0.0916\texamples: 1866 (2.1%)\n",
      "white              TNR: 0.9911\tFNR: 0.0707\texamples: 1849 (2.1%)\n",
      "indian             TNR: 0.9912\tFNR: 0.0827\texamples: 1888 (2.1%)\n",
      "straight           TNR: 0.9913\tFNR: 0.0558\texamples: 1814 (2.0%)\n",
      "older              TNR: 0.9921\tFNR: 0.1035\texamples: 1805 (2.0%)\n",
      "american           TNR: 0.9926\tFNR: 0.0684\texamples: 3835 (4.3%)\n",
      "lgbt               TNR: 0.9932\tFNR: 0.1005\texamples: 1808 (2.0%)\n",
      "christian          TNR: 0.9934\tFNR: 0.0869\texamples: 1881 (2.1%)\n",
      "middle eastern     TNR: 0.9935\tFNR: 0.0809\texamples: 1892 (2.1%)\n",
      "protestant         TNR: 0.9935\tFNR: 0.0525\texamples: 1881 (2.1%)\n",
      "african american   TNR: 0.9936\tFNR: 0.0804\texamples: 1892 (2.1%)\n",
      "young              TNR: 0.9936\tFNR: 0.1353\texamples: 1875 (2.1%)\n",
      "african            TNR: 0.9936\tFNR: 0.0980\texamples: 3778 (4.2%)\n",
      "asian              TNR: 0.9937\tFNR: 0.0945\texamples: 1893 (2.1%)\n",
      "japanese           TNR: 0.9938\tFNR: 0.1435\texamples: 1902 (2.1%)\n",
      "younger            TNR: 0.9938\tFNR: 0.1156\texamples: 1959 (2.2%)\n",
      "buddhist           TNR: 0.9939\tFNR: 0.0899\texamples: 1956 (2.2%)\n",
      "european           TNR: 0.9940\tFNR: 0.1052\texamples: 1944 (2.2%)\n",
      "canadian           TNR: 0.9947\tFNR: 0.1591\texamples: 1889 (2.1%)\n"
     ]
    }
   ],
   "source": [
    "def print_terms_negative_rates():\n",
    "    with open(MADLIBS_TERMS_PATH) as f:\n",
    "        madlibs_terms = [term.strip() for term in f.readlines()]\n",
    "\n",
    "    for rec in sorted(terms_negative_rates(madlibs, madlibs_terms), key=lambda d: d['tnr']):\n",
    "        size, term, tnr, fnr = rec['size'], rec['term'], rec['tnr'], rec['fnr']\n",
    "        print('{:18s} TNR: {:.4f}\\tFNR: {:.4f}\\texamples: {} ({:.1f}%)'.format(\n",
    "            term, tnr, fnr, size, 100 * (size / len(madlibs)))) \n",
    "\n",
    "print_terms_negative_rates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
