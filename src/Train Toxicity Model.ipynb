{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Toxicity Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a model to detect toxicity in online comments. It uses a CNN architecture for text classification trained on the [Wikipedia Talk Labels: Toxicity dataset](https://figshare.com/articles/Wikipedia_Talk_Labels_Toxicity/4563973) and pre-trained GloVe embeddings which can be found at:\n",
    "http://nlp.stanford.edu/data/glove.6B.zip\n",
    "(source page: http://nlp.stanford.edu/projects/glove/).\n",
    "\n",
    "This model is a modification of [example code](https://github.com/fchollet/keras/blob/master/examples/pretrained_word_embeddings.py) found in the [Keras Github repository](https://github.com/fchollet/keras) and released under an [MIT license](https://github.com/fchollet/keras/blob/master/LICENSE). For further details of this license, find it [online](https://github.com/fchollet/keras/blob/master/LICENSE) or in this repository in the file KERAS_LICENSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Instructions\n",
    "(TODO: nthain) - Move to README\n",
    "\n",
    "Prior to running the notebook, you must:\n",
    "\n",
    "* Download the [Wikipedia Talk Labels: Toxicity dataset](https://figshare.com/articles/Wikipedia_Talk_Labels_Toxicity/4563973)\n",
    "* Download pre-trained [GloVe embeddings](http://nlp.stanford.edu/data/glove.6B.zip)\n",
    "* (optional) To skip the training step, you will need to download a model and tokenizer file. We are looking into the appropriate means for distributing these (sometimes large) files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model_tool import ToxModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLITS = ['train', 'dev', 'test']\n",
    "\n",
    "wiki = {}\n",
    "debias = {}\n",
    "random = {}\n",
    "for split in SPLITS:\n",
    "    wiki[split] = '../data/wiki_%s.csv' % split\n",
    "    debias[split] = '../data/wiki_debias_%s.csv' % split\n",
    "    random[split] = '../data/wiki_debias_random_%s.csv' % split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/3\n",
      "95692/95692 [==============================] - 1010s - loss: 0.1466 - acc: 0.9486 - val_loss: 0.1271 - val_acc: 0.9537\n",
      "Epoch 2/3\n",
      "95692/95692 [==============================] - 974s - loss: 0.1006 - acc: 0.9642 - val_loss: 0.1088 - val_acc: 0.9625\n",
      "Epoch 3/3\n",
      "95692/95692 [==============================] - 970s - loss: 0.0900 - acc: 0.9674 - val_loss: 0.1255 - val_acc: 0.9626\n",
      "<keras.callbacks.History object at 0x126974a50>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'cnn_wiki_tox_v1'\n",
    "wiki_model = ToxModel()\n",
    "wiki_model.train(wiki['train'], wiki['dev'], text_column = 'comment', label_column = 'is_toxic', model_name = MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97421504710290929"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_model.prep_data_and_score(wiki['test'], text_column = 'comment', label_column = 'is_toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 99157 samples, validate on 33283 samples\n",
      "Epoch 1/3\n",
      "99157/99157 [==============================] - 1030s - loss: 0.1438 - acc: 0.9496 - val_loss: 0.1004 - val_acc: 0.9632\n",
      "Epoch 2/3\n",
      "99157/99157 [==============================] - 1015s - loss: 0.1024 - acc: 0.9638 - val_loss: 0.1023 - val_acc: 0.9641\n",
      "Epoch 3/3\n",
      "99157/99157 [==============================] - 1036s - loss: 0.0911 - acc: 0.9677 - val_loss: 0.1107 - val_acc: 0.9642\n",
      "<keras.callbacks.History object at 0x15923ad50>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'cnn_debias_tox_v1'\n",
    "debias_model = ToxModel()\n",
    "debias_model.train(debias['train'], debias['dev'], text_column = 'comment', label_column = 'is_toxic', model_name = MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96419152565392841"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debias_model.prep_data_and_score(debias['test'], text_column = 'comment', label_column = 'is_toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 99157 samples, validate on 33283 samples\n",
      "Epoch 1/3\n",
      "99157/99157 [==============================] - 1025s - loss: 0.1425 - acc: 0.9500 - val_loss: 0.1153 - val_acc: 0.9600\n",
      "Epoch 2/3\n",
      "99157/99157 [==============================] - 1020s - loss: 0.0991 - acc: 0.9646 - val_loss: 0.0984 - val_acc: 0.9645\n",
      "Epoch 3/3\n",
      "99157/99157 [==============================] - 1015s - loss: 0.0892 - acc: 0.9675 - val_loss: 0.1471 - val_acc: 0.9461\n",
      "<keras.callbacks.History object at 0x13b35dc50>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'cnn_debias_random_tox_v1'\n",
    "debias_random_model = ToxModel()\n",
    "debias_random_model.train(random['train'], random['dev'], text_column = 'comment', label_column = 'is_toxic', model_name = MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97254224449423554"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debias_random_model.prep_data_and_score(random['test'], text_column = 'comment', label_column = 'is_toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
