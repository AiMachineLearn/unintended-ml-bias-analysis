{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pkg_resources\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import model_bias_analysis\n",
    "\n",
    "# autoreload makes it easier to interactively work on code in the model_bias_analysis module.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shared functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_boolean_labels(labels):\n",
    "    return np.where(labels >= 0.5, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scatterplot(results, model_1, model_2, y_label, ylim=(0.8, 1.0)):\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #bar_width = 0.35\n",
    "    point_size=15\n",
    "    for i, (_index, row) in enumerate(results.iterrows()):\n",
    "        # For each subgroup, we plot a 1D scatterplot. The x-value is the position\n",
    "        # of the item in the dataframe. To change the ordering of the subgroups,\n",
    "        # sort the dataframe before passing to this function.\n",
    "        x = [i] * 2\n",
    "        y = [row[model_1], row[model_2]]\n",
    "        ax.scatter(x, y, s=0)\n",
    "        #if (abs(y[1] - y[0]) > 0.003):\n",
    "        plt.arrow(x[0],y[0], 0, y[1] - y[0], length_includes_head=True, shape='full', head_starts_at_zero=False, head_length=0.005, head_width=0.3, color='black')\n",
    "    ax.set_xticklabels(results['subgroup'], rotation=90)\n",
    "    ax.set_xticks(range(len(results)))\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.set_title(y_label)\n",
    "    fig.tight_layout()\n",
    "    #fig.savefig('/tmp/%s_%s.eps' % (file_name, values_col), format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MADLIBS set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_families = [\n",
    "    ['Rock:TOXICITY'],#, 'wiki_cnn_v3_101', 'wiki_cnn_v3_102'],\n",
    "    ['RockV5_1:TOXICITY'],# 'wiki_debias_cnn_v3_101', 'wiki_debias_cnn_v3_102'],\n",
    "    ['RockV6_1:TOXICITY'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "madlibs = pd.read_csv('eval_datasets/bias_madlibs_77k_scored_prod_models.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add columns for each subgroup.\n",
    "f = open('bias_madlibs_data/adjectives_people.txt', 'r')\n",
    "terms = [line.strip() for line in f]\n",
    "model_bias_analysis.add_subgroup_columns_from_text(madlibs, 'Text', terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "madlibs['label_bool'] = madlibs.apply(lambda row: row.Label == 'BAD', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "madlibs_results = model_bias_analysis.per_subgroup_aucs(madlibs, terms, model_families, 'label_bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "madlibs_results['TOXICITY_V1_pinned_auc'] = madlibs_results.apply(lambda row: row['Rock:TOXICITY_aucs'][0], axis=1)\n",
    "madlibs_results['TOXICITY_V5_pinned_auc'] = madlibs_results.apply(lambda row: row['RockV5_1:TOXICITY_aucs'][0], axis=1)\n",
    "madlibs_results['TOXICITY_V6_pinned_auc'] = madlibs_results.apply(lambda row: row['RockV6_1:TOXICITY_aucs'][0], axis=1)\n",
    "\n",
    "madlibs_results['TOXICITY_V1_weighted_pinned_auc'] = madlibs_results.apply(lambda row: row['Rock:TOXICITY_normalized_pinned_aucs'][0], axis=1)\n",
    "madlibs_results['TOXICITY_V5_weighted_pinned_auc'] = madlibs_results.apply(lambda row: row['RockV5_1:TOXICITY_normalized_pinned_aucs'][0], axis=1)\n",
    "madlibs_results['TOXICITY_V6_weighted_pinned_auc'] = madlibs_results.apply(lambda row: row['RockV6_1:TOXICITY_normalized_pinned_aucs'][0], axis=1)\n",
    "\n",
    "madlibs_results['TOXICITY_V1_negative_aeg'] = madlibs_results.apply(lambda row: row['Rock:TOXICITY_within_negative_label_mwus'][0], axis=1)\n",
    "madlibs_results['TOXICITY_V5_negative_aeg'] = madlibs_results.apply(lambda row: row['RockV5_1:TOXICITY_within_negative_label_mwus'][0], axis=1)\n",
    "madlibs_results['TOXICITY_V6_negative_aeg'] = madlibs_results.apply(lambda row: row['RockV6_1:TOXICITY_within_negative_label_mwus'][0], axis=1)\n",
    "\n",
    "madlibs_results['TOXICITY_V1_positive_aeg'] = madlibs_results.apply(lambda row: row['Rock:TOXICITY_within_positive_label_mwus'][0], axis=1)\n",
    "madlibs_results['TOXICITY_V5_positive_aeg'] = madlibs_results.apply(lambda row: row['RockV5_1:TOXICITY_within_positive_label_mwus'][0], axis=1)\n",
    "madlibs_results['TOXICITY_V6_positive_aeg'] = madlibs_results.apply(lambda row: row['RockV6_1:TOXICITY_within_positive_label_mwus'][0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Real Data set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "human_labels = [\n",
    " 'toxicity',\n",
    " 'severe_toxicity',\n",
    " 'obscene',\n",
    " 'sexual_explicit',\n",
    " 'identity_attack',\n",
    " 'insult',\n",
    " 'threat',\n",
    " 'male',\n",
    " 'female',\n",
    " 'transgender',\n",
    " 'other_gender',\n",
    " 'heterosexual',\n",
    " 'homosexual_gay_or_lesbian',\n",
    " 'bisexual',\n",
    " 'other_sexual_orientation',\n",
    " 'christian',\n",
    " 'jewish',\n",
    " 'muslim',\n",
    " 'hindu',\n",
    " 'buddhist',\n",
    " 'atheist',\n",
    " 'other_religion',\n",
    " 'black',\n",
    " 'white',\n",
    " 'asian',\n",
    " 'latino',\n",
    " 'other_race_or_ethnicity',\n",
    " 'physical_disability',\n",
    " 'intellectual_or_learning_disability',\n",
    " 'psychiatric_or_mental_illness',\n",
    " 'other_disability']\n",
    "\n",
    "identities = [\n",
    " 'male',\n",
    " 'female',\n",
    " 'transgender',\n",
    " 'heterosexual',\n",
    " 'homosexual_gay_or_lesbian',\n",
    " 'bisexual',\n",
    " 'christian',\n",
    " 'jewish',\n",
    " 'muslim',\n",
    " 'hindu',\n",
    " 'buddhist',\n",
    " 'atheist',\n",
    " 'other_religion',\n",
    " 'black',\n",
    " 'white',\n",
    " 'asian',\n",
    " 'latino',\n",
    " 'other_race_or_ethnicity',\n",
    " 'physical_disability',\n",
    " 'intellectual_or_learning_disability',\n",
    " 'psychiatric_or_mental_illness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_data = pd.read_csv('eval_datasets/identity_labeled_scored.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_data_model_families = [\n",
    "    ['rock_toxicity'],#, 'wiki_cnn_v3_101', 'wiki_cnn_v3_102'],\n",
    "    ['rock_v6_1_toxicity'],# 'wiki_debias_cnn_v3_101', 'wiki_debias_cnn_v3_102'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for human_label in human_labels:\n",
    "    real_data[human_label] = convert_to_boolean_labels(real_data[human_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "real_data_results = model_bias_analysis.per_subgroup_aucs(real_data, identities, real_data_model_families, 'toxicity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_results['TOXICITY_V1_pinned_auc'] = real_data_results.apply(lambda row: row['rock_toxicity_aucs'][0], axis=1)\n",
    "real_data_results['TOXICITY_V6_pinned_auc'] = real_data_results.apply(lambda row: row['rock_v6_1_toxicity_aucs'][0], axis=1)\n",
    "\n",
    "real_data_results['TOXICITY_V1_weighted_pinned_auc'] = real_data_results.apply(lambda row: row['rock_toxicity_normalized_pinned_aucs'][0], axis=1)\n",
    "real_data_results['TOXICITY_V6_weighted_pinned_auc'] = real_data_results.apply(lambda row: row['rock_v6_1_toxicity_normalized_pinned_aucs'][0], axis=1)\n",
    "\n",
    "real_data_results['TOXICITY_V1_negative_aeg'] = real_data_results.apply(lambda row: row['rock_toxicity_within_negative_label_mwus'][0], axis=1)\n",
    "real_data_results['TOXICITY_V6_negative_aeg'] = real_data_results.apply(lambda row: row['rock_v6_1_toxicity_within_negative_label_mwus'][0], axis=1)\n",
    "\n",
    "real_data_results['TOXICITY_V1_positive_aeg'] = real_data_results.apply(lambda row: row['rock_toxicity_within_positive_label_mwus'][0], axis=1)\n",
    "real_data_results['TOXICITY_V6_positive_aeg'] = real_data_results.apply(lambda row: row['rock_v6_1_toxicity_within_positive_label_mwus'][0], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot(madlibs_results, 'TOXICITY_V1_pinned_auc', 'TOXICITY_V6_pinned_auc', 'Synthetic Data Pinned AUC')\n",
    "scatterplot(madlibs_results, 'TOXICITY_V1_weighted_pinned_auc', 'TOXICITY_V6_weighted_pinned_auc', 'Synthetic Data Weighted Pinned AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot(madlibs_results, 'TOXICITY_V1_negative_aeg', 'TOXICITY_V6_negative_aeg', 'Synthetic Data Negative AEG', ylim=(-0.5,0.5))\n",
    "scatterplot(madlibs_results, 'TOXICITY_V1_positive_aeg', 'TOXICITY_V6_positive_aeg', 'Synthetic Data Positive AEG', ylim=(-0.5,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# REAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot(real_data_results, 'TOXICITY_V1_pinned_auc', 'TOXICITY_V6_pinned_auc', 'Real Data Pinned AUC', ylim=(0.5,1.0))\n",
    "scatterplot(real_data_results, 'TOXICITY_V1_weighted_pinned_auc', 'TOXICITY_V6_weighted_pinned_auc', 'Real Data Weighted Pinned AUC', ylim=(0.5,1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot(real_data_results, 'TOXICITY_V1_negative_aeg', 'TOXICITY_V6_negative_aeg', 'Real Data Negative AEG', ylim=(-0.5,0.5))\n",
    "scatterplot(real_data_results, 'TOXICITY_V1_positive_aeg', 'TOXICITY_V6_positive_aeg', 'Real Data Positive AEG', ylim=(-0.5,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = madlibs_results[['subgroup', 'TOXICITY_V1_pinned_auc', 'TOXICITY_V6_pinned_auc', 'TOXICITY_V1_weighted_pinned_auc', 'TOXICITY_V6_weighted_pinned_auc', 'TOXICITY_V1_negative_aeg', 'TOXICITY_V6_negative_aeg', 'TOXICITY_V1_positive_aeg', 'TOXICITY_V6_positive_aeg']]\n",
    "out.to_csv('eval_datasets/bias_madlibs_77k_scored_prod_models_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_real = real_data_results[['subgroup', 'TOXICITY_V1_pinned_auc', 'TOXICITY_V6_pinned_auc', 'TOXICITY_V1_weighted_pinned_auc', 'TOXICITY_V6_weighted_pinned_auc', 'TOXICITY_V1_negative_aeg', 'TOXICITY_V6_negative_aeg', 'TOXICITY_V1_positive_aeg', 'TOXICITY_V6_positive_aeg']]\n",
    "out_real.to_csv('eval_datasets/identity_labeled_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_scores = real_data.query('toxicity == True')['rock_toxicity']\n",
    "non_toxic_scores = real_data.query('toxicity == False')['rock_toxicity']\n",
    "sns.distplot( non_toxic_scores , color=\"skyblue\", axlabel='all')\n",
    "sns.distplot( toxic_scores , color=\"red\", axlabel='all')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_scores = real_data.query('toxicity == True')['rock_v6_1_toxicity']\n",
    "non_toxic_scores = real_data.query('toxicity == False')['rock_v6_1_toxicity']\n",
    "sns.distplot( non_toxic_scores , color=\"skyblue\", axlabel='all')\n",
    "sns.distplot( toxic_scores , color=\"red\", axlabel='all')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_histogram(data, identity, model, label_col='toxicity'):\n",
    "    toxic_scores = data.query(identity + ' == True & ' + label_col + ' == True')[model]\n",
    "    non_toxic_scores = data.query(identity + ' == True & '+ label_col + ' == False')[model]\n",
    "    sns.distplot( non_toxic_scores , color=\"skyblue\", axlabel=identity)\n",
    "    sns.distplot( toxic_scores , color=\"red\", axlabel=identity)\n",
    "    plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(real_data, 'homosexual_gay_or_lesbian', 'rock_toxicity')\n",
    "plot_histogram(real_data, 'homosexual_gay_or_lesbian', 'rock_v6_1_toxicity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(real_data, 'heterosexual', 'rock_toxicity')\n",
    "plot_histogram(real_data, 'heterosexual', 'rock_v6_1_toxicity')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(real_data, 'transgender', 'rock_toxicity')\n",
    "plot_histogram(real_data, 'transgender', 'rock_v6_1_toxicity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(madlibs, 'transgender', 'Rock:TOXICITY', label_col='label_bool')\n",
    "plot_histogram(madlibs, 'transgender', 'RockV5_1:TOXICITY', label_col='label_bool')\n",
    "plot_histogram(madlibs, 'transgender', 'RockV6_1:TOXICITY', label_col='label_bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_data['diff'] = real_data['rock_v6_1_toxicity'] - real_data['rock_toxicity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look = real_data[real_data['homosexual_gay_or_lesbian'] & (real_data.comment_text.str.len() < 100)].sort_values('diff', ascending=False)[['comment_text', 'rock_v6_1_toxicity', 'rock_toxicity', 'toxicity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look[look.toxicity]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
